# LiveLipNet-Duo: Real-Time Dual-Speaker Lipreading
Abstract
LiveLipNet-Duo: Real-Time Dual-Speaker Lipreading

LiveLipNet-Duo presents a novel approach in assistive technologies for overcoming the com- munication barriers for the individuals with hearing impairments. Our model leverages the synergy between the spatiotemporal convolutions and recurrent neural network architectures to transcribe the real-time interpretation of speech from two speakers simultaneously. For the elim- ination of the manual segmentation, we employ the connectionist temporal classification (CTC) loss which enables direct, end-to-end training from unprocessed video input to textual tran- scription. We are additionally developing an extensive dataset with recordings from a diverse groups of speakers (2 males and 2 females) with varied backgrounds to guarantee robustness and generalization in lipreading training. This project aims not only to improve accessibility for those with hearing impairments, but also extends the use of lipreading into loud environments, where other speech recognition systems that rely solely on audio are ineffective.
